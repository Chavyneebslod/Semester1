@article{1314553,
 author = {Saar-Tsechansky, Maytal and Provost, Foster},
 title = {Handling Missing Values when Applying Classification Models},
 journal = {J. Mach. Learn. Res.},
 volume = {8},
 year = {2007},
 issn = {1532-4435},
 pages = {1623--1657},
 publisher = {JMLR.org},
 }

@article{citeulike:4732435,
    abstract = {We consider the problem of learning classifiers in structured domains, where some objects have a subset of features that are inherently absent due to complex relationships between the features. Unlike the case where a feature exists but its value is not observed, here we focus on the case where a feature may not even exist (structurally absent) for some of the samples. The common approach for handling missing features in discriminative models is to first complete their unknown values, and then use a standard classification procedure over the completed data. This paper focuses on features that are known to be non-existing, rather than have an unknown value. We show how incomplete data can be classified  directly  without any completion of the missing features using a max-margin learning framework. We formulate an objective function, based on the geometric interpretation of the margin, that aims to maximize the margin of each sample in its own relevant subspace. In this formulation, the linearly separable case can be transformed into a binary search over a series of second order cone programs (SOCP), a convex problem that can be solved efficiently. We also describe two approaches for optimizing the general case: an approximation that can be solved as a standard quadratic program (QP) and an iterative approach for solving the exact problem. By avoiding the pre-processing phase in which the data is completed, both of these approaches could offer considerable computational savings. More importantly, we show that the elegant handling of missing values by our approach allows it to both outperform other methods when the missing values have non-trivial structure, and be competitive with other methods when the values are missing at random. We demonstrate our results on several standard benchmarks and two real-world problems: edge prediction in metabolic pathways, and automobile detection in natural images.},
    address = {Cambridge, MA, USA},
    author = {Chechik, Gal and Heitz, Geremy and Elidan, Gal and Abbeel, Pieter and Koller, Daphne},
    citeulike-article-id = {4732435},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390681.1390682},
    issn = {1533-7928},
    journal = {J. Mach. Learn. Res.},
    keywords = {mldm},
    pages = {1--21},
    posted-at = {2010-09-27 12:17:03},
    priority = {2},
    publisher = {MIT Press},
    title = {Max-margin Classification of Data with Absent Features},
    url = {http://portal.acm.org/citation.cfm?id=1390681.1390682},
    volume = {9},
    year = {2008}
}
